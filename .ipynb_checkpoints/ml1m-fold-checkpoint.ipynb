{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pandas 1.2.0 version\n",
      "Using seaborn 0.11.1 version\n",
      "Using scipy 1.6.0 version\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.model_selection import (\n",
    "    GroupKFold,\n",
    "    GroupShuffleSplit,\n",
    "    KFold,\n",
    "    ShuffleSplit,\n",
    "    StratifiedKFold,\n",
    "    StratifiedShuffleSplit,\n",
    "    TimeSeriesSplit,\n",
    ")\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "print(\"Using pandas %s version\" % pd.__version__)\n",
    "print(\"Using seaborn %s version\" % sns.__version__)\n",
    "print(\"Using scipy %s version\" % scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_names = [\"MovieID\", \"Title\", \"Genres\"]\n",
    "\n",
    "movies = pd.read_table(\n",
    "    r\"C:\\Projects\\RecSys2020\\datasets\\ml1m\\movies.dat\",\n",
    "    sep=\"::\",\n",
    "    header=None,\n",
    "    names=movies_names,\n",
    "    encoding=\"latin-1\",\n",
    "    engine=\"python\",\n",
    ")\n",
    "\n",
    "movies.head()\n",
    "\n",
    "ratings_names = [\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"]\n",
    "\n",
    "ratings = pd.read_table(\n",
    "    r\"C:\\Projects\\RecSys2020\\datasets\\ml1m\\ratings.dat\",\n",
    "    sep=\"::\",\n",
    "    header=None,\n",
    "    engine=\"python\",\n",
    "    names=ratings_names,\n",
    ")\n",
    "\n",
    "ratings.head()\n",
    "\n",
    "\n",
    "users_names = [\"UserID\", \"Gender\", \"Age\", \"Occupation\", \"Zip-code\"]\n",
    "\n",
    "users = pd.read_table(\n",
    "    r\"C:\\Projects\\RecSys2020\\datasets\\ml1m\\users.dat\",\n",
    "    sep=\"::\",\n",
    "    engine=\"python\",\n",
    "    header=None,\n",
    "    names=users_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one merged DataFrame\n",
    "movie_ratings = pd.merge(movies, ratings)\n",
    "lens = pd.merge(movie_ratings, users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'number of ratings by Gender': Gender\n",
      "F    246440\n",
      "M    753769\n",
      "dtype: int64,\n",
      "    'unique users by Gender':         UserID\n",
      "Gender        \n",
      "F         1709\n",
      "M         4331}\n",
      "{   'number of ratings by Age': Age\n",
      "1      27211\n",
      "18    183536\n",
      "25    395556\n",
      "35    199003\n",
      "45     83633\n",
      "50     72490\n",
      "56     38780\n",
      "dtype: int64,\n",
      "    'unique users by Age':      UserID\n",
      "Age        \n",
      "1       222\n",
      "18     1103\n",
      "25     2096\n",
      "35     1193\n",
      "45      550\n",
      "50      496\n",
      "56      380}\n",
      "{   'number of ratings by Occupation': Occupation\n",
      "0     130499\n",
      "1      85351\n",
      "2      50068\n",
      "3      31623\n",
      "4     131032\n",
      "5      21850\n",
      "6      37205\n",
      "7     105425\n",
      "8       2706\n",
      "9      11345\n",
      "10     23290\n",
      "11     20563\n",
      "12     57214\n",
      "13     13754\n",
      "14     49109\n",
      "15     22951\n",
      "16     46021\n",
      "17     72816\n",
      "18     12086\n",
      "19     14904\n",
      "20     60397\n",
      "dtype: int64,\n",
      "    'unique users by Occupation':             UserID\n",
      "Occupation        \n",
      "0              711\n",
      "1              528\n",
      "2              267\n",
      "3              173\n",
      "4              759\n",
      "5              112\n",
      "6              236\n",
      "7              679\n",
      "8               17\n",
      "9               92\n",
      "10             195\n",
      "11             129\n",
      "12             388\n",
      "13             142\n",
      "14             302\n",
      "15             144\n",
      "16             241\n",
      "17             502\n",
      "18              70\n",
      "19              72\n",
      "20             281}\n"
     ]
    }
   ],
   "source": [
    "lens.head()\n",
    "lens.describe()\n",
    "\n",
    "# Age\n",
    "rating_by_age = lens.groupby(\"Age\").size()\n",
    "users_by_age = lens.groupby(\"Age\").agg({\"UserID\": pd.Series.nunique})\n",
    "# pp.pprint({'number of ratings by age':rating_by, 'unique users by age':users_by})\n",
    "\n",
    "\n",
    "def groupby(by):\n",
    "    r = lens.groupby(by).size()\n",
    "    u = lens.groupby(by).agg({\"UserID\": pd.Series.nunique})\n",
    "    pp.pprint({\"number of ratings by \" + by: r, \"unique users by \" + by: u})\n",
    "\n",
    "\n",
    "for i in [\"Gender\", \"Age\", \"Occupation\"]:\n",
    "    groupby(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "1      27211\n",
       "18    183536\n",
       "25    395556\n",
       "35    199003\n",
       "45     83633\n",
       "50     72490\n",
       "56     38780\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_by_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Under 18</th>\n",
       "      <th>18-24</th>\n",
       "      <th>25-34</th>\n",
       "      <th>35-44</th>\n",
       "      <th>45-49</th>\n",
       "      <th>50-55</th>\n",
       "      <th>56+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ratings</th>\n",
       "      <td>27211</td>\n",
       "      <td>183536</td>\n",
       "      <td>395556</td>\n",
       "      <td>199003</td>\n",
       "      <td>83633</td>\n",
       "      <td>72490</td>\n",
       "      <td>38780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>users</th>\n",
       "      <td>[222]</td>\n",
       "      <td>[1103]</td>\n",
       "      <td>[2096]</td>\n",
       "      <td>[1193]</td>\n",
       "      <td>[550]</td>\n",
       "      <td>[496]</td>\n",
       "      <td>[380]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Under 18   18-24   25-34   35-44  45-49  50-55    56+\n",
       "ratings    27211  183536  395556  199003  83633  72490  38780\n",
       "users      [222]  [1103]  [2096]  [1193]  [550]  [496]  [380]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = {\n",
    "    1: \"Under 18\",\n",
    "    18: \"18-24\",\n",
    "    25: \"25-34\",\n",
    "    35: \"35-44\",\n",
    "    45: \"45-49\",\n",
    "    50: \"50-55\",\n",
    "    56: \"56+\",\n",
    "}\n",
    "\n",
    "pd.DataFrame(\n",
    "    data=[rating_by_age.tolist(), np.array(users_by_age)],\n",
    "    index=[\"ratings\", \"users\"],\n",
    "    columns=age.values(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gender = {\"F\": \"Female\", \"M\": \"Male\"}\n",
    "age = {\n",
    "    1: \"Under 18\",\n",
    "    18: \"18-24\",\n",
    "    25: \"25-34\",\n",
    "    35: \"35-44\",\n",
    "    45: \"45-49\",\n",
    "    50: \"50-55\",\n",
    "    56: \"56+\",\n",
    "}\n",
    "occupation = {\n",
    "    0: \"other or not specified\",\n",
    "    1: \"academic/educator\",\n",
    "    2: \"artist\",\n",
    "    3: \"clerical/admin\",\n",
    "    4: \"college/grad student\",\n",
    "    5: \"customer service\",\n",
    "    6: \"doctor/health care\",\n",
    "    7: \"executive/managerial\",\n",
    "    8: \"farmer\",\n",
    "    9: \"homemaker\",\n",
    "    10: \"K-12 student\",\n",
    "    11: \"lawyer\",\n",
    "    12: \"programmer\",\n",
    "    13: \"retired\",\n",
    "    14: \"sales/marketing\",\n",
    "    15: \"scientist\",\n",
    "    16: \"self-employed\",\n",
    "    17: \"technician/engineer\",\n",
    "    18: \"tradesman/craftsman\",\n",
    "    19: \"unemployed\",\n",
    "    20: \"writer\",\n",
    "}\n",
    "names = {\"Gender\": gender, \"Age\": age, \"Occupation\": occupation}\n",
    "\n",
    "\n",
    "def getNames(by: string):\n",
    "    return names[by]\n",
    "\n",
    "\n",
    "def groupby2(by):\n",
    "    r = lens.groupby(by).size()\n",
    "    u = lens.groupby(by).agg({\"UserID\": pd.Series.nunique})\n",
    "    # pp.pprint({'number of ratings by '+ by:r, 'unique users by '+by:u})\n",
    "    ppp = pd.DataFrame(\n",
    "        data=[r.tolist(), np.array(u)],\n",
    "        index=[\"ratings\", \"users\"],\n",
    "        columns=getNames(by).values(),\n",
    "    )\n",
    "    return ppp\n",
    "\n",
    "\n",
    "e = []\n",
    "for i in [\"Gender\", \"Age\", \"Occupation\"]:\n",
    "    e.append(groupby2(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>246440</td>\n",
       "      <td>[1709]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>753769</td>\n",
       "      <td>[4331]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ratings   users\n",
       "Female  246440  [1709]\n",
       "Male    753769  [4331]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# gender = {'M': 'Male', 'F': 'Female'}\n",
    "# age = {\n",
    "#     1:\"Under 18\",\n",
    "#    18:\"18-24\",\n",
    "#    25:\"25-34\",\n",
    "#    35:\"35-44\",\n",
    "#    45:\"45-49\",\n",
    "#    50:\"50-55\",\n",
    "#    56:\"56+\"}\n",
    "# occupation = {0:\"other or not specified\",\n",
    "#     1:\"academic/educator\",\n",
    "#     2:\"artist\",\n",
    "#     3:\"clerical/admin\",\n",
    "#     4:\"college/grad student\",\n",
    "#     5:\"customer service\",\n",
    "#     6:\"doctor/health care\",\n",
    "#     7:\"executive/managerial\",\n",
    "#     8:\"farmer\",\n",
    "#     9:\"homemaker\",\n",
    "#    10:\"K-12 student\",\n",
    "#    11:\"lawyer\",\n",
    "#    12:\"programmer\",\n",
    "#    13:\"retired\",\n",
    "#    14:\"sales/marketing\",\n",
    "#    15:\"scientist\",\n",
    "#    16:\"self-employed\",\n",
    "#    17:\"technician/engineer\",\n",
    "#    18:\"tradesman/craftsman\",\n",
    "#    19:\"unemployed\",\n",
    "#    20:\"writer\"}\n",
    "# names = {\"Gender\":gender, \"Age\":age, \"Occupation\":occupation}\n",
    "# def getNames(by: string):\n",
    "#    return names[by]\n",
    "\n",
    "# def groupby2(by):\n",
    "#    r = lens.groupby(by).size()\n",
    "#    u = lens.groupby(by).agg({\"UserID\": pd.Series.nunique})\n",
    "#    u = u.replace({by:getNames(by)})\n",
    "#    pp.pprint({'number of ratings by '+ by:r, 'unique users by '+by:u})\n",
    "\n",
    "# for i in [\"Gender\", \"Age\", \"Occupation\"]:\n",
    "#    groupby2(i)\n",
    "\n",
    "\n",
    "# print(rating_by_age.axes)\n",
    "# print(rating_by_age)\n",
    "# print(rating_by_age.replace({'Age':age}))\n",
    "\n",
    "# rating_by_age.reindex([\"Under 18\",\n",
    "# \"18-24\",\n",
    "# \"25-34\",\n",
    "# \"35-44\",\n",
    "# \"45-49\",\n",
    "# \"50-55\",\n",
    "# \"56+\"])#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirM = r\"C:\\Projects\\RecSys2020\\datasets\\ml1m\\male\\\\\"\n",
    "data_dirF = r\"C:\\Projects\\RecSys2020\\datasets\\ml1m\\female\\\\\"\n",
    "\n",
    "fr = lens[lens[\"Gender\"] == \"F\"].sort_values(by=\"UserID\")\n",
    "mr = lens[lens[\"Gender\"] == \"M\"].sort_values(by=\"UserID\")\n",
    "\n",
    "rating_columns = [\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"]\n",
    "fname = \"data.txt\"\n",
    "params = dict(index=False, header=False, columns=rating_columns, sep=\"\\t\")\n",
    "fr.to_csv(os.path.join(data_dirF, fname), **params)\n",
    "mr.to_csv(os.path.join(data_dirM, fname), **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the class/group data\n",
    "n_points = len(lens)\n",
    "lens[\"sexcode\"] = pd.factorize(lens[\"Gender\"])[0] + 1\n",
    "ageGroups = pd.factorize(lens[\"Age\"])[0] + 1\n",
    "occupationGroups = pd.factorize(lens[\"Occupation\"])[0] + 1\n",
    "timestampGroups = pd.factorize(lens[\"Timestamp\"])[0] + 1\n",
    "\n",
    "X = np.array(lens[\"Rating\"])  # np.random.randn(100, 10)\n",
    "y = np.array(lens[\"sexcode\"]).T\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "np.random.seed(1338)\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.model_selection._split.KFold'> 0\n",
      "<class 'sklearn.model_selection._split.GroupKFold'> 1\n",
      "<class 'sklearn.model_selection._split.ShuffleSplit'> 2\n",
      "<class 'sklearn.model_selection._split.StratifiedKFold'> 0\n",
      "<class 'sklearn.model_selection._split.StratifiedShuffleSplit'> 1\n",
      "<class 'sklearn.model_selection._split.TimeSeriesSplit'> 2\n"
     ]
    }
   ],
   "source": [
    "def plot_cv_indices(cv, X, y, group, group2, ax, n_splits, lw=10):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(\n",
    "            range(len(indices)),\n",
    "            [ii + 0.5] * len(indices),\n",
    "            c=indices,\n",
    "            marker=\"_\",\n",
    "            lw=lw,\n",
    "            cmap=cmap_cv,\n",
    "            vmin=-0.2,\n",
    "            vmax=1.2,\n",
    "        )\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 1.5] * len(X), c=y, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 2.5] * len(X), c=group, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 3.5] * len(X), c=group2, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    # Formatting\n",
    "    labels = [\"Lytis\", \"Amžius\", \"Užsiėmimas\"]\n",
    "    yticklabels = list(range(n_splits)) + labels\n",
    "    ax.set(\n",
    "        yticks=np.arange(n_splits + 3) + 0.5,\n",
    "        yticklabels=yticklabels,\n",
    "        xlabel=\"Imties indeksas\",\n",
    "        ylabel=\"Kryžminės patikros padalijimas\",\n",
    "        ylim=[n_splits + len(labels) + 0.2, -0.2],\n",
    "        xlim=[0, n_points],\n",
    "    )\n",
    "    ax.set_title(type(cv).__name__, fontsize=12)\n",
    "    return ax\n",
    "\n",
    "\n",
    "# cvs = [KFold]\n",
    "# ,GroupKFold, ShuffleSplit, StratifiedKFold,\n",
    "# GroupShuffleSplit, StratifiedShuffleSplit, TimeSeriesSplit]\n",
    "\n",
    "\n",
    "cvs1 = [KFold, GroupKFold, ShuffleSplit]\n",
    "cvs2 = [\n",
    "    StratifiedKFold,\n",
    "    ##GroupShuffleSplit,\n",
    "    StratifiedShuffleSplit,\n",
    "    TimeSeriesSplit,\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(2, 3)\n",
    "\n",
    "for i, cv in enumerate(cvs1):\n",
    "    print(cv, i)\n",
    "    this_cv = cv(n_splits=n_splits)\n",
    "    ax = axs[0, i]\n",
    "    plot_cv_indices(this_cv, X, y, ageGroups, occupationGroups, ax, n_splits)\n",
    "\n",
    "\n",
    "for i, cv in enumerate(cvs2):\n",
    "    print(cv, i)\n",
    "    this_cv = cv(n_splits=n_splits)\n",
    "    ax = axs[1, i]\n",
    "    plot_cv_indices(this_cv, X, y, ageGroups, occupationGroups, ax, n_splits)\n",
    "\n",
    "\n",
    "ax.legend(\n",
    "    [Patch(color=cmap_cv(0.8)), Patch(color=cmap_cv(0.02))],\n",
    "    [\"Testavimo aibė\", \"Mokymo aibė\"],\n",
    "    loc=(1.02, 0.8),\n",
    ")\n",
    "# Make the legend fit\n",
    "fig.set_size_inches(12, 6)\n",
    "\n",
    "plt.tight_layout()\n",
    "png = os.path.join(r\"C:\\Projects\\RecSys2020\\results\\figure0.cross-validations.png\")\n",
    "fig.savefig(png, format=\"png\", dpi=300)\n",
    "\n",
    "png = os.path.join(\n",
    "    r\"E:\\OneDrive\\MSThesis\\_2019\\master_thesis_template_vu_mif_cs1-master\\master_thesis_template_vu_mif_cs1-master\\_third_part\\img\\figure0.cross-validations.png\"\n",
    ")\n",
    "fig.savefig(png, format=\"png\", dpi=300)\n",
    "\n",
    "# fig.subplots_adjust(right=0.7)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166701\n",
      "166704\n",
      "333405\n",
      "500106\n",
      "666807\n",
      "833508\n"
     ]
    }
   ],
   "source": [
    "cv = TimeSeriesSplit(n_splits)\n",
    "splits = []\n",
    "for ii, (tr, tt) in enumerate(cv.split(X=lens, y=y, groups=timestampGroups)):\n",
    "    splits.append((tr, tt))\n",
    "\n",
    "print(len(splits[0][1]))\n",
    "\n",
    "for i in splits:\n",
    "    print(len(i[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[166704, 166701], [333405, 166701], [500106, 166701], [666807, 166701], [833508, 166701]]\n"
     ]
    }
   ],
   "source": [
    "print([[len(t) for t in split] for split in splits])\n",
    "splited = [[t for t in split] for split in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for split in splits:\n",
    "    print(len(split))\n",
    "# 1-data-test.txt\n",
    "# 1-data-train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"C:\\Projects\\RecSys2020\\datasets\\ml1m\\\\\"\n",
    "cvs = [\n",
    "    KFold,\n",
    "    GroupKFold,\n",
    "    ShuffleSplit,\n",
    "    StratifiedKFold,\n",
    "    GroupShuffleSplit,\n",
    "    StratifiedShuffleSplit,\n",
    "    TimeSeriesSplit,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = TimeSeriesSplit(n_splits)\n",
    "for fold, (train, test) in enumerate(cv.split(X=lens, y=y, groups=timestampGroups)):\n",
    "    fold += 1\n",
    "    print(fold)\n",
    "    print(fold, \" train=\", len(lens[lens.index.isin(splits[i][0])]))\n",
    "    print(fold, \" test=\", len(lens[lens.index.isin(splits[i][1])]))\n",
    "\n",
    "    train = lens[[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"]][lens.index.isin(train)]\n",
    "    test = lens[[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"]][lens.index.isin(test)]\n",
    "    cv_name = type(cv).__name__\n",
    "    dirr = os.path.join(data_dir, cv_name)\n",
    "\n",
    "    train.to_csv(os.path.join(dirr, str(fold) + \"-data-train.txt\"))\n",
    "    test.to_csv(os.path.join(dirr, str(fold) + \"-data-test.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>978824351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "      <td>978301777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "1       1       48       5  978824351\n",
       "2       1      150       5  978301777"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens[[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"]][lens.index.isin(splits[i][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(cvs, groups):\n",
    "    for cv in cvs:\n",
    "        this_cv = cv(n_splits=n_splits)\n",
    "        this_cv_name = type(this_cv).__name__\n",
    "        dir = os.path.join(data_dir, this_cv_name)\n",
    "        if not os.path.exists(dir):\n",
    "            os.mkdir(dir)\n",
    "\n",
    "        for fold, (train, test) in enumerate(this_cv.split(X=lens, y=y, groups=groups)):\n",
    "            fold += 1\n",
    "            print()\n",
    "            print(this_cv_name, fold, \" train=\", len(lens[lens.index.isin(train)]))\n",
    "            print(this_cv_name, fold, \" test=\", len(lens[lens.index.isin(test)]))\n",
    "\n",
    "            train = lens[[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"]][\n",
    "                lens.index.isin(train)\n",
    "            ]\n",
    "            test = lens[[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"]][\n",
    "                lens.index.isin(test)\n",
    "            ]\n",
    "\n",
    "            train.to_csv(\n",
    "                os.path.join(dir, str(fold) + \"-data-train.txt\"),\n",
    "                index=False,\n",
    "                header=False,\n",
    "                sep=\"\\t\",\n",
    "            )\n",
    "            test.to_csv(\n",
    "                os.path.join(dir, str(fold) + \"-data-test.txt\"),\n",
    "                index=False,\n",
    "                header=False,\n",
    "                sep=\"\\t\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KFold 1  train= 800167\n",
      "KFold 1  test= 200042\n",
      "\n",
      "KFold 2  train= 800167\n",
      "KFold 2  test= 200042\n",
      "\n",
      "KFold 3  train= 800167\n",
      "KFold 3  test= 200042\n",
      "\n",
      "KFold 4  train= 800167\n",
      "KFold 4  test= 200042\n",
      "\n",
      "KFold 5  train= 800168\n",
      "KFold 5  test= 200041\n",
      "\n",
      "ShuffleSplit 1  train= 900188\n",
      "ShuffleSplit 1  test= 100021\n",
      "\n",
      "ShuffleSplit 2  train= 900188\n",
      "ShuffleSplit 2  test= 100021\n",
      "\n",
      "ShuffleSplit 3  train= 900188\n",
      "ShuffleSplit 3  test= 100021\n",
      "\n",
      "ShuffleSplit 4  train= 900188\n",
      "ShuffleSplit 4  test= 100021\n",
      "\n",
      "ShuffleSplit 5  train= 900188\n",
      "ShuffleSplit 5  test= 100021\n",
      "\n",
      "StratifiedKFold 1  train= 800167\n",
      "StratifiedKFold 1  test= 200042\n",
      "\n",
      "StratifiedKFold 2  train= 800167\n",
      "StratifiedKFold 2  test= 200042\n",
      "\n",
      "StratifiedKFold 3  train= 800167\n",
      "StratifiedKFold 3  test= 200042\n",
      "\n",
      "StratifiedKFold 4  train= 800167\n",
      "StratifiedKFold 4  test= 200042\n",
      "\n",
      "StratifiedKFold 5  train= 800168\n",
      "StratifiedKFold 5  test= 200041\n",
      "\n",
      "GroupShuffleSplit 1  train= 753769\n",
      "GroupShuffleSplit 1  test= 246440\n",
      "\n",
      "GroupShuffleSplit 2  train= 753769\n",
      "GroupShuffleSplit 2  test= 246440\n",
      "\n",
      "GroupShuffleSplit 3  train= 753769\n",
      "GroupShuffleSplit 3  test= 246440\n",
      "\n",
      "GroupShuffleSplit 4  train= 246440\n",
      "GroupShuffleSplit 4  test= 753769\n",
      "\n",
      "GroupShuffleSplit 5  train= 246440\n",
      "GroupShuffleSplit 5  test= 753769\n",
      "\n",
      "StratifiedShuffleSplit 1  train= 900188\n",
      "StratifiedShuffleSplit 1  test= 100021\n",
      "\n",
      "StratifiedShuffleSplit 2  train= 900188\n",
      "StratifiedShuffleSplit 2  test= 100021\n",
      "\n",
      "StratifiedShuffleSplit 3  train= 900188\n",
      "StratifiedShuffleSplit 3  test= 100021\n",
      "\n",
      "StratifiedShuffleSplit 4  train= 900188\n",
      "StratifiedShuffleSplit 4  test= 100021\n",
      "\n",
      "StratifiedShuffleSplit 5  train= 900188\n",
      "StratifiedShuffleSplit 5  test= 100021\n",
      "\n",
      "TimeSeriesSplit 1  train= 166704\n",
      "TimeSeriesSplit 1  test= 166701\n",
      "\n",
      "TimeSeriesSplit 2  train= 333405\n",
      "TimeSeriesSplit 2  test= 166701\n",
      "\n",
      "TimeSeriesSplit 3  train= 500106\n",
      "TimeSeriesSplit 3  test= 166701\n",
      "\n",
      "TimeSeriesSplit 4  train= 666807\n",
      "TimeSeriesSplit 4  test= 166701\n",
      "\n",
      "TimeSeriesSplit 5  train= 833508\n",
      "TimeSeriesSplit 5  test= 166701\n"
     ]
    }
   ],
   "source": [
    "def split(cvs, groups):\n",
    "    for cv in cvs:\n",
    "        this_cv = cv(n_splits=n_splits)\n",
    "        this_cv_name = type(this_cv).__name__\n",
    "        dir = os.path.join(data_dir, this_cv_name)\n",
    "        if not os.path.exists(dir):\n",
    "            os.mkdir(dir)\n",
    "\n",
    "        for fold, (train, test) in enumerate(this_cv.split(X=lens, y=y, groups=groups)):\n",
    "            fold += 1\n",
    "            print()\n",
    "            print(this_cv_name, fold, \" train=\", len(lens[lens.index.isin(train)]))\n",
    "            print(this_cv_name, fold, \" test=\", len(lens[lens.index.isin(test)]))\n",
    "\n",
    "            train = lens[[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"]][\n",
    "                lens.index.isin(train)\n",
    "            ]\n",
    "            test = lens[[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"]][\n",
    "                lens.index.isin(test)\n",
    "            ]\n",
    "\n",
    "            train.to_csv(\n",
    "                os.path.join(dir, str(fold) + \"-data-train.txt\"),\n",
    "                index=False,\n",
    "                header=False,\n",
    "                sep=\"\\t\",\n",
    "            )\n",
    "            test.to_csv(\n",
    "                os.path.join(dir, str(fold) + \"-data-test.txt\"),\n",
    "                index=False,\n",
    "                header=False,\n",
    "                sep=\"\\t\",\n",
    "            )\n",
    "\n",
    "\n",
    "data_dir = r\"C:\\Projects\\RecSys2020\\datasets\\ml1m\\\\\"\n",
    "cvs = [KFold, ShuffleSplit, StratifiedKFold, GroupShuffleSplit, StratifiedShuffleSplit]\n",
    "split(cvs, np.array(lens[\"sexcode\"]).T)\n",
    "split([TimeSeriesSplit], timestampGroups)\n",
    "# , TimeSeriesSplit, GroupKFold]\n",
    "# g = np.array(lens['sexcode']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (TargetSampling)",
   "language": "python",
   "name": "pycharm-960a82ab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
